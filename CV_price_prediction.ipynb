{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CV_price_prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a9e627a4d5f9449881e866d24f2d7a2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f3af49c3d5ab4b5c8b6db1bed2c17d08",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4d42ef2b49214bf49429a2cdb5878f83",
              "IPY_MODEL_a46aedc64742493f93c1d6abb2551441"
            ]
          }
        },
        "f3af49c3d5ab4b5c8b6db1bed2c17d08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4d42ef2b49214bf49429a2cdb5878f83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6586cceea57749ec8c637988fd819473",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a53085dfb331411a9a1aac26b48de43c"
          }
        },
        "a46aedc64742493f93c1d6abb2551441": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7d05abf3b683428199dd6d10a083ce34",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 367/? [05:39&lt;00:00,  1.08it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_591199cde3d64b0da0770ce4823cd84e"
          }
        },
        "6586cceea57749ec8c637988fd819473": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a53085dfb331411a9a1aac26b48de43c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7d05abf3b683428199dd6d10a083ce34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "591199cde3d64b0da0770ce4823cd84e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b43b4f14ba61407684f31c979d9cf8f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e8a7e3753c3047d8aa3449a0c672a840",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5413938f9ac84a328fc98efb2d0c731e",
              "IPY_MODEL_89f8bc3c8cf2411084b41252fa3efa97"
            ]
          }
        },
        "e8a7e3753c3047d8aa3449a0c672a840": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5413938f9ac84a328fc98efb2d0c731e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_269d1d5cf2e648b8b5fe9bfe49d43da6",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 46827520,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 46827520,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_13458ce28c7a421795c41fa972a1e361"
          }
        },
        "89f8bc3c8cf2411084b41252fa3efa97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_620bd842c01a4d7d99f7f2cafcbff97b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 44.7M/44.7M [00:00&lt;00:00, 100MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_94da22ac3f5940088796f4d009c16056"
          }
        },
        "269d1d5cf2e648b8b5fe9bfe49d43da6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "13458ce28c7a421795c41fa972a1e361": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "620bd842c01a4d7d99f7f2cafcbff97b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "94da22ac3f5940088796f4d009c16056": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HD4XmU9sgM7c",
        "colab_type": "text"
      },
      "source": [
        "# Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQo2LXt7fwQd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "93680ee9-13d2-435f-97bd-c0e3eb46220f"
      },
      "source": [
        "!pip install selenium\n",
        "!apt-get update # to update ubuntu to correctly run apt install\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "import sys\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "from selenium import webdriver\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "wd = webdriver.Chrome('chromedriver',chrome_options=chrome_options)\n",
        "# wd.get(\"https://www.webite-url.com\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting selenium\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/d6/4294f0b4bce4de0abf13e17190289f9d0613b0a44e5dd6a7f5ca98459853/selenium-3.141.0-py2.py3-none-any.whl (904kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 911kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from selenium) (1.24.3)\n",
            "Installing collected packages: selenium\n",
            "Successfully installed selenium-3.141.0\n",
            "Ign:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:2 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n",
            "Get:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release [564 B]\n",
            "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [801 B]\n",
            "Get:6 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:7 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:8 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease [3,626 B]\n",
            "Get:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release.gpg [833 B]\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:11 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease [15.4 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Ign:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n",
            "Get:14 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Packages [38.7 kB]\n",
            "Get:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [151 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:16 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main Sources [1,840 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [1,253 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [1,397 kB]\n",
            "Get:19 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main amd64 Packages [888 kB]\n",
            "Fetched 5,841 kB in 6s (1,022 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-codecs-ffmpeg-extra\n",
            "Suggested packages:\n",
            "  webaccounts-chromium-extension unity-chromium-extension adobe-flashplugin\n",
            "The following NEW packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-chromedriver\n",
            "  chromium-codecs-ffmpeg-extra\n",
            "0 upgraded, 4 newly installed, 0 to remove and 53 not upgraded.\n",
            "Need to get 75.5 MB of archives.\n",
            "After this operation, 256 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-codecs-ffmpeg-extra amd64 83.0.4103.61-0ubuntu0.18.04.1 [1,119 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser amd64 83.0.4103.61-0ubuntu0.18.04.1 [66.7 MB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser-l10n all 83.0.4103.61-0ubuntu0.18.04.1 [3,378 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-chromedriver amd64 83.0.4103.61-0ubuntu0.18.04.1 [4,294 kB]\n",
            "Fetched 75.5 MB in 9s (8,725 kB/s)\n",
            "Selecting previously unselected package chromium-codecs-ffmpeg-extra.\n",
            "(Reading database ... 144328 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-codecs-ffmpeg-extra_83.0.4103.61-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-codecs-ffmpeg-extra (83.0.4103.61-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser.\n",
            "Preparing to unpack .../chromium-browser_83.0.4103.61-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-browser (83.0.4103.61-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser-l10n.\n",
            "Preparing to unpack .../chromium-browser-l10n_83.0.4103.61-0ubuntu0.18.04.1_all.deb ...\n",
            "Unpacking chromium-browser-l10n (83.0.4103.61-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "Preparing to unpack .../chromium-chromedriver_83.0.4103.61-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (83.0.4103.61-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-codecs-ffmpeg-extra (83.0.4103.61-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser (83.0.4103.61-0ubuntu0.18.04.1) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Setting up chromium-chromedriver (83.0.4103.61-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser-l10n (83.0.4103.61-0ubuntu0.18.04.1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: use options instead of chrome_options\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6elRaUJLgl6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "f283fb9b-7207-4f27-f799-64e15cf4db60"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcLh7HKXf02j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e101a6ad-4e6f-4234-de66-47901f8b9d27"
      },
      "source": [
        "pip install bs4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.6/dist-packages (0.0.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from bs4) (4.6.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZQIeDSnctDL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# posts[0].find(\"a\", { \"class\":\"result-image gallery\"})['data-ids'].split(',')[0].split(':')[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umEw672xaMvP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # print(posts[0])\n",
        "# [\"https://images.craigslist.org/{}_300x300.jpg\".format(i[2:]) for i in posts[0].find(\"a\", { \"class\":\"result-image gallery\"})['data-ids'].split(',')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3sdz1qhYFZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# response.url"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l524WBb2gRnU",
        "colab_type": "text"
      },
      "source": [
        "# Web scrap from craiglist\n",
        "\n",
        "I only scrapped 5 pages, which have 600 items in total. These items may not be unique so I then dropped duplicates."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joPKNhXdBBAS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "outputId": "77f9adb7-112c-4d6b-f475-a96850de47ab"
      },
      "source": [
        "from requests import get\n",
        "\n",
        "#get the first page of the east bay housing prices\n",
        "# response = get('https://sfbay.craigslist.org/search/eby/apa?hasPic=1&availabilityMode=0') #get rid of those lame-o's that post a housing option without a pic using their filter\n",
        "response = get('https://sfbay.craigslist.org/search/eby/sss?query=furniture&hasPic=1&availabilityMode=0')\n",
        "from bs4 import BeautifulSoup\n",
        "html_soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "\n",
        "from time import sleep\n",
        "import re\n",
        "from random import randint #avoid throttling by not sending too many requests one after the other\n",
        "from warnings import warn\n",
        "from time import time\n",
        "from IPython.core.display import clear_output\n",
        "import numpy as np\n",
        "from bs4.element import Tag\n",
        "# find the total number of posts to find the limit of the pagination\n",
        "results_num = html_soup.find('div', class_= 'search-legend')\n",
        "results_total = int(results_num.find('span', class_='totalcount').text) #pulled the total count of posts as the upper bound of the pages array\n",
        "\n",
        "#each page has 119 posts so each new page is defined as follows: s=120, s=240, s=360, and so on. So we need to step in size 120 in the np.arange function\n",
        "# pages = np.arange(0, results_total+1, 120)\n",
        "k = 5\n",
        "pages = np.arange(0, 120*k,120) \n",
        "\n",
        "iterations = 0\n",
        "\n",
        "post_timing = []\n",
        "post_hoods = []\n",
        "post_title_texts = []\n",
        "bedroom_counts = []\n",
        "sqfts = []\n",
        "post_links = []\n",
        "post_prices = []\n",
        "post_img = []\n",
        "\n",
        "for page in pages:\n",
        "    \n",
        "    #get request\n",
        "    response = get(\"https://sfbay.craigslist.org/search/eby/sss?\" \n",
        "                   +'query=furniture'\n",
        "                   + \"&hasPic=1\"\n",
        "                   + \"&availabilityMode=0\"\n",
        "                   + \"&s=\" #the parameter for defining the page number \n",
        "                   + str(page)) #the page number in the pages array from earlier)\n",
        "    print(response.url)\n",
        "\n",
        "    sleep(randint(1,5))\n",
        "     \n",
        "    #throw warning for status codes that are not 200\n",
        "    if response.status_code != 200:\n",
        "        warn('Request: {}; Status code: {}'.format(requests, response.status_code))\n",
        "        \n",
        "    #define the html text\n",
        "    page_html = BeautifulSoup(response.text, 'html.parser')\n",
        "    \n",
        "    #define the posts\n",
        "    posts = page_html.find_all('li', class_= 'result-row')\n",
        "    \n",
        "    #extract data item-wise\n",
        "    for post in posts:\n",
        "\n",
        "        if post.find('span', class_ = 'result-hood') is not None:\n",
        "\n",
        "            #posting date\n",
        "            #grab the datetime element 0 for date and 1 for time\n",
        "            post_datetime = post.find('time', class_= 'result-date')['datetime']\n",
        "            post_timing.append(post_datetime)\n",
        "\n",
        "            #neighborhoods\n",
        "            post_hood = post.find('span', class_= 'result-hood').text\n",
        "            post_hoods.append(post_hood)\n",
        "\n",
        "            #title text\n",
        "            post_title = post.find('a', class_='result-title hdrlnk')\n",
        "            post_title_text = post_title.text\n",
        "            post_title_texts.append(post_title_text)\n",
        "\n",
        "            #post link\n",
        "            post_link = post_title['href']\n",
        "            post_links.append(post_link)\n",
        "            \n",
        "            #removes the \\n whitespace from each side, removes the currency symbol, and turns it into an int\n",
        "            post_price = int(post.a.text.strip().replace(\"$\", \"\")) \n",
        "            post_prices.append(post_price)\n",
        "\n",
        "            image_id = post.find(\"a\", { \"class\":\"result-image gallery\"})['data-ids'].split(',')[0].split(':')[1]\n",
        "            post_img.append(\"https://images.craigslist.org/{}_300x300.jpg\".format(image_id))\n",
        "            \n",
        "            if post.find('span', class_ = 'housing') is not None:\n",
        "                \n",
        "                #if the first element is accidentally square footage\n",
        "                if 'ft2' in post.find('span', class_ = 'housing').text.split()[0]:\n",
        "                    \n",
        "                    #make bedroom nan\n",
        "                    bedroom_count = np.nan\n",
        "                    bedroom_counts.append(bedroom_count)\n",
        "                    \n",
        "                    #make sqft the first element\n",
        "                    sqft = int(post.find('span', class_ = 'housing').text.split()[0][:-3])\n",
        "                    sqfts.append(sqft)\n",
        "                    \n",
        "                #if the length of the housing details element is more than 2\n",
        "                elif len(post.find('span', class_ = 'housing').text.split()) > 2:\n",
        "                    \n",
        "                    #therefore element 0 will be bedroom count\n",
        "                    bedroom_count = post.find('span', class_ = 'housing').text.replace(\"br\", \"\").split()[0]\n",
        "                    bedroom_counts.append(bedroom_count)\n",
        "                    \n",
        "                    #and sqft will be number 3, so set these here and append\n",
        "                    sqft = int(post.find('span', class_ = 'housing').text.split()[2][:-3])\n",
        "                    sqfts.append(sqft)\n",
        "                    \n",
        "                #if there is num bedrooms but no sqft\n",
        "                elif len(post.find('span', class_ = 'housing').text.split()) == 2:\n",
        "                    \n",
        "                    #therefore element 0 will be bedroom count\n",
        "                    bedroom_count = post.find('span', class_ = 'housing').text.replace(\"br\", \"\").split()[0]\n",
        "                    bedroom_counts.append(bedroom_count)\n",
        "                    \n",
        "                    #and sqft will be number 3, so set these here and append\n",
        "                    sqft = np.nan\n",
        "                    sqfts.append(sqft)                    \n",
        "                \n",
        "                else:\n",
        "                    bedroom_count = np.nan\n",
        "                    bedroom_counts.append(bedroom_count)\n",
        "                \n",
        "                    sqft = np.nan\n",
        "                    sqfts.append(sqft)\n",
        "                \n",
        "            #if none of those conditions catch, make bedroom nan, this won't be needed    \n",
        "            else:\n",
        "                bedroom_count = np.nan\n",
        "                bedroom_counts.append(bedroom_count)\n",
        "                \n",
        "                sqft = np.nan\n",
        "                sqfts.append(sqft)\n",
        "            #    bedroom_counts.append(bedroom_count)\n",
        "                \n",
        "            #    sqft = np.nan\n",
        "            #    sqfts.append(sqft)\n",
        "                \n",
        "    iterations += 1\n",
        "    print(\"Page \" + str(iterations) + \" scraped successfully!\")\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Scrape complete!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://sfbay.craigslist.org/search/eby/sss?query=furniture&hasPic=1&availabilityMode=0&s=0\n",
            "Page 1 scraped successfully!\n",
            "https://sfbay.craigslist.org/search/eby/sss?query=furniture&hasPic=1&availabilityMode=0&s=120\n",
            "Page 2 scraped successfully!\n",
            "https://sfbay.craigslist.org/search/eby/sss?query=furniture&hasPic=1&availabilityMode=0&s=240\n",
            "Page 3 scraped successfully!\n",
            "https://sfbay.craigslist.org/search/eby/sss?query=furniture&hasPic=1&availabilityMode=0&s=360\n",
            "Page 4 scraped successfully!\n",
            "https://sfbay.craigslist.org/search/eby/sss?query=furniture&hasPic=1&availabilityMode=0&s=480\n",
            "Page 5 scraped successfully!\n",
            "\n",
            "\n",
            "Scrape complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5G1j-2bHgYcU",
        "colab_type": "text"
      },
      "source": [
        "# Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYjh9pp_LF_O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 822
        },
        "outputId": "d2ccedd1-e53b-4b68-c07d-0c0625c419a3"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "furniture_df = pd.DataFrame({'posted': post_timing,\n",
        "                       'neighborhood': post_hoods,\n",
        "                       'post title': post_title_texts,\n",
        "                        'URL': post_links,\n",
        "                       'price': post_prices,\n",
        "                        'img_url': post_img})\n",
        "print(furniture_df.info())\n",
        "furniture_df.head(100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 572 entries, 0 to 571\n",
            "Data columns (total 6 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   posted        572 non-null    object\n",
            " 1   neighborhood  572 non-null    object\n",
            " 2   post title    572 non-null    object\n",
            " 3   URL           572 non-null    object\n",
            " 4   price         572 non-null    int64 \n",
            " 5   img_url       572 non-null    object\n",
            "dtypes: int64(1), object(5)\n",
            "memory usage: 26.9+ KB\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>posted</th>\n",
              "      <th>neighborhood</th>\n",
              "      <th>post title</th>\n",
              "      <th>URL</th>\n",
              "      <th>price</th>\n",
              "      <th>img_url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-06-21 13:10</td>\n",
              "      <td>(oakland rockridge / claremont)</td>\n",
              "      <td>Light Fixtures (ceiling and table lights)</td>\n",
              "      <td>https://sfbay.craigslist.org/eby/fuo/d/oakland...</td>\n",
              "      <td>100</td>\n",
              "      <td>https://images.craigslist.org/00o0o_g4kQl9LfY8...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-06-21 13:11</td>\n",
              "      <td>(oakland rockridge / claremont)</td>\n",
              "      <td>Pair of Barcelona style leather chairs</td>\n",
              "      <td>https://sfbay.craigslist.org/eby/fuo/d/oakland...</td>\n",
              "      <td>600</td>\n",
              "      <td>https://images.craigslist.org/00505_7ucMALkGHT...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-06-21 13:11</td>\n",
              "      <td>(oakland rockridge / claremont)</td>\n",
              "      <td>Roche Bobois leather chair</td>\n",
              "      <td>https://sfbay.craigslist.org/eby/fuo/d/oakland...</td>\n",
              "      <td>400</td>\n",
              "      <td>https://images.craigslist.org/00F0F_jY1kH784Sy...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-06-21 13:12</td>\n",
              "      <td>(oakland rockridge / claremont)</td>\n",
              "      <td>Danish modern Bent Karlby Osterport Pendant Light</td>\n",
              "      <td>https://sfbay.craigslist.org/eby/fuo/d/oakland...</td>\n",
              "      <td>500</td>\n",
              "      <td>https://images.craigslist.org/00o0o_ibAlHH1LNf...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-06-21 13:12</td>\n",
              "      <td>(brentwood / oakley)</td>\n",
              "      <td>STILL AVAILABLE PRICE DROP!! VINTAGE PROJECTIO...</td>\n",
              "      <td>https://sfbay.craigslist.org/eby/fuo/d/discove...</td>\n",
              "      <td>85</td>\n",
              "      <td>https://images.craigslist.org/00s0s_ePR7WkWsdF...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>2020-06-21 12:24</td>\n",
              "      <td>(oakland west)</td>\n",
              "      <td>Luxurious bedroom furniture set ($350 or best ...</td>\n",
              "      <td>https://sfbay.craigslist.org/eby/fuo/d/oakland...</td>\n",
              "      <td>350</td>\n",
              "      <td>https://images.craigslist.org/00Q0Q_fU5fIiM3an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>2020-06-21 12:24</td>\n",
              "      <td>(oakland west)</td>\n",
              "      <td>Beautiful tufted ottoman</td>\n",
              "      <td>https://sfbay.craigslist.org/eby/fuo/d/oakland...</td>\n",
              "      <td>100</td>\n",
              "      <td>https://images.craigslist.org/00M0M_awRtniivFH...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>2020-06-21 12:24</td>\n",
              "      <td>(oakland west)</td>\n",
              "      <td>TV Stand - perfect condition (IKEA)</td>\n",
              "      <td>https://sfbay.craigslist.org/eby/fuo/d/oakland...</td>\n",
              "      <td>25</td>\n",
              "      <td>https://images.craigslist.org/00O0O_ghDiwzvYYh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>2020-06-21 12:24</td>\n",
              "      <td>(oakland west)</td>\n",
              "      <td>Beautiful Japanese room divider 7'</td>\n",
              "      <td>https://sfbay.craigslist.org/eby/fuo/d/oakland...</td>\n",
              "      <td>150</td>\n",
              "      <td>https://images.craigslist.org/00I0I_bMUVQeh7HL...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>2020-06-21 12:24</td>\n",
              "      <td>(oakland west)</td>\n",
              "      <td>Office desk-- distressed brown and black wood</td>\n",
              "      <td>https://sfbay.craigslist.org/eby/fuo/d/oakland...</td>\n",
              "      <td>150</td>\n",
              "      <td>https://images.craigslist.org/00q0q_10PK4jaxj8...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows Ã— 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              posted  ...                                            img_url\n",
              "0   2020-06-21 13:10  ...  https://images.craigslist.org/00o0o_g4kQl9LfY8...\n",
              "1   2020-06-21 13:11  ...  https://images.craigslist.org/00505_7ucMALkGHT...\n",
              "2   2020-06-21 13:11  ...  https://images.craigslist.org/00F0F_jY1kH784Sy...\n",
              "3   2020-06-21 13:12  ...  https://images.craigslist.org/00o0o_ibAlHH1LNf...\n",
              "4   2020-06-21 13:12  ...  https://images.craigslist.org/00s0s_ePR7WkWsdF...\n",
              "..               ...  ...                                                ...\n",
              "95  2020-06-21 12:24  ...  https://images.craigslist.org/00Q0Q_fU5fIiM3an...\n",
              "96  2020-06-21 12:24  ...  https://images.craigslist.org/00M0M_awRtniivFH...\n",
              "97  2020-06-21 12:24  ...  https://images.craigslist.org/00O0O_ghDiwzvYYh...\n",
              "98  2020-06-21 12:24  ...  https://images.craigslist.org/00I0I_bMUVQeh7HL...\n",
              "99  2020-06-21 12:24  ...  https://images.craigslist.org/00q0q_10PK4jaxj8...\n",
              "\n",
              "[100 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iM9JSHtv-hVG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4bf630bf-7d1f-42f2-a30a-cf564854b1c3"
      },
      "source": [
        "len(furniture_df.img_url.unique())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "563"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZED-mlYxp18e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "furniture_df = furniture_df.drop_duplicates('img_url')\n",
        "furniture_df = furniture_df[furniture_df['price']!=0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4ewqMWhk0_s",
        "colab_type": "text"
      },
      "source": [
        "Dataset size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACSSxWKvpXAz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "30ec44c1-8342-4873-f05b-1deb3c1bab79"
      },
      "source": [
        "len(furniture_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "529"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UT94IMqnqVJr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0483d8db-b43d-4a2b-f2a3-7e9f273174c8"
      },
      "source": [
        "!rm -r data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'data': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgWWRJTXdzUB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir data\n",
        "!mkdir data/train\n",
        "!mkdir data/val\n",
        "!mkdir data/test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTtiQJwiPzGp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import pandas as pd\n",
        "# furniture_df = pd.read_csv('/content/drive/My Drive/furniture.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7X-_TnWV1U1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "0367246c-25a7-4ed1-e5aa-226905adeb45"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = []\n",
        "for i, row in furniture_df.iterrows():\n",
        "    x.append(row.price)\n",
        "plt.hist(x, bins= 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([386.,  96.,  25.,  11.,   2.,   1.,   4.,   0.,   0.,   4.]),\n",
              " array([1.0000e+00, 3.0090e+02, 6.0080e+02, 9.0070e+02, 1.2006e+03,\n",
              "        1.5005e+03, 1.8004e+03, 2.1003e+03, 2.4002e+03, 2.7001e+03,\n",
              "        3.0000e+03]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FW6ef-1wkqB-",
        "colab_type": "text"
      },
      "source": [
        "I only select the items that its price is less than 2000."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZx94wCGhpiJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "furniture_df =furniture_df[furniture_df['price'] <=2000]\n",
        "train, test = train_test_split(furniture_df, test_size=0.2,random_state = 42)\n",
        "train, val = train_test_split(train, test_size = 0.125, random_state = 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gI7p3AyZLJ6P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "furniture_df.to_csv('/content/drive/My Drive/furniture.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iQqtY3SIoWa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = train.reset_index()\n",
        "val = val.reset_index()\n",
        "test = test.reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5fmFJDagdis",
        "colab_type": "text"
      },
      "source": [
        "normalize price feature because the range of price is from 0 to 2000."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4oQz7hxX0Yq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn\n",
        "from sklearn.preprocessing import normalize\n",
        "X = np.array(train['price']).reshape(1, -1)\n",
        "normalizer = sklearn.preprocessing.Normalizer().fit(X)\n",
        "train['price'] = normalizer.transform(X)[0]\n",
        "\n",
        "X = np.array(val['price']).reshape(1, -1)\n",
        "normalizer = sklearn.preprocessing.Normalizer().fit(X)\n",
        "val['price'] = normalizer.transform(X)[0]\n",
        "\n",
        "X = np.array(test['price']).reshape(1, -1)\n",
        "normalizer = sklearn.preprocessing.Normalizer().fit(X)\n",
        "test['price'] = normalizer.transform(X)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJBDXf2kfbc1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tqdm \n",
        "from tqdm import tqdm_notebook"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9Zh6Zwhgoyo",
        "colab_type": "text"
      },
      "source": [
        "# Download image data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sy05otdMdp_B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135,
          "referenced_widgets": [
            "a9e627a4d5f9449881e866d24f2d7a2e",
            "f3af49c3d5ab4b5c8b6db1bed2c17d08",
            "4d42ef2b49214bf49429a2cdb5878f83",
            "a46aedc64742493f93c1d6abb2551441",
            "6586cceea57749ec8c637988fd819473",
            "a53085dfb331411a9a1aac26b48de43c",
            "7d05abf3b683428199dd6d10a083ce34",
            "591199cde3d64b0da0770ce4823cd84e"
          ]
        },
        "outputId": "0a826fc3-243e-449f-8bdd-880d1f3027b8"
      },
      "source": [
        "%cd data/train\n",
        "import urllib.request\n",
        "import os\n",
        "for i, row in tqdm_notebook(train.iterrows()):\n",
        "  img_url = row.img_url\n",
        "  img_name = os.path.basename(img_url)\n",
        "  local_filename, headers = urllib.request.urlretrieve(img_url,img_name)\n",
        "  # print(local_filename, headers)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/data/train\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a9e627a4d5f9449881e866d24f2d7a2e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQTp2yKBlmw9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f3bf2f1e-0f7c-4921-ad19-0270e287188b"
      },
      "source": [
        "%cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-b5bgZXkh32L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "26f73e4b-c1e2-4cdd-de7a-015c8d4aedd1"
      },
      "source": [
        "%cd val\n",
        "for i, row in val.iterrows():\n",
        "  img_url = row.img_url\n",
        "  img_name = os.path.basename(img_url)\n",
        "  urllib.request.urlretrieve(img_url,img_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/data/val\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzPYZQVgh4LY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "904bcfe8-17b9-41de-8258-b41f490c5e38"
      },
      "source": [
        "%cd ..\n",
        "%cd test\n",
        "for i, row in test.iterrows():\n",
        "  img_url = row.img_url\n",
        "  img_name = os.path.basename(img_url)\n",
        "  urllib.request.urlretrieve(img_url,img_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/data\n",
            "/content/data/test\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tz29hwWPgsA5",
        "colab_type": "text"
      },
      "source": [
        "# Transfer Learning Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_xN9LdOf_A_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4c2c29b1-4a93-4ce2-a5a2-bafde12c0c00"
      },
      "source": [
        "# TODO: INSERT CODE HERE\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "# from torchvision.datasets import FashionMNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import pandas as pd\n",
        "import dill\n",
        "import skimage\n",
        "from skimage import io\n",
        "import torchvision\n",
        "import torch.utils.data as data\n",
        "from torchvision import datasets, models, transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "import os\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqqwsldKf_iN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_size = 224\n",
        "input_transforms = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.Resize((input_size, input_size)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1ax120ltWDr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e8a7c834-5b71-4768-fdb1-9993bf741d29"
      },
      "source": [
        "%cd ..\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/data\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzfZ5n8DsUI-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %cd ~\n",
        "# %cd /content\n",
        "# x_train, x_val, x_test = [], [], []\n",
        "# y_train, y_val, y_test = [], [], []\n",
        "# for i, row in train.iterrows():\n",
        "#   # print(row.img_url.split('//')[1].split('/')[1])\n",
        "#   x_train.append(torch.tensor(io.imread(os.path.join('data/train/room', row.img_url.split('//')[1].split('/')[1]))))\n",
        "#   y_train.append(torch.tensor(row.price))\n",
        "# for i, row in val.iterrows():\n",
        "#   # print(row.img_url.split('//')[1].split('/')[1])\n",
        "#   x_val.append(torch.tensor(io.imread(os.path.join('data/val/room', row.img_url.split('//')[1].split('/')[1]))))\n",
        "#   y_val.append(torch.tensor(row.price))\n",
        "# for i, row in test.iterrows():\n",
        "#   # print(row.img_url.split('//')[1].split('/')[1])\n",
        "#   x_test.append(torch.tensor(io.imread(os.path.join('data/test/room', row.img_url.split('//')[1].split('/')[1]))))\n",
        "#   y_test.append(torch.tensor(row.price))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxSDwMdrHLf_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxkIZ_ZugvKu",
        "colab_type": "text"
      },
      "source": [
        "## Define customized PyTorch dataset structure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiuTKmSAvg38",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FurnitureDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataset, data_type, transform):\n",
        "\n",
        "        self.dataset = dataset\n",
        "        self.transform = transform\n",
        "        self.data_type = data_type\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        row = self.dataset.loc[idx]\n",
        "        image = io.imread(os.path.join('data/'+ self.data_type, row.img_url.split('//')[1].split('/')[1]))\n",
        "        price = row.price\n",
        "        \n",
        "\n",
        "        image = self.transform(image)\n",
        "\n",
        "        return (image, price)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1U5XSTBmGr4R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = FurnitureDataset(train, 'train', input_transforms)\n",
        "val_dataset = FurnitureDataset(val, 'val', input_transforms)\n",
        "test_dataset = FurnitureDataset(test, 'test', input_transforms)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKinZlTVucXZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4)\n",
        "val_loader = DataLoader(val_dataset,  batch_size=8,shuffle=True, num_workers=4)\n",
        "test_loader = DataLoader(test_dataset,  batch_size=8,shuffle=True, num_workers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmVajTxWg0uR",
        "colab_type": "text"
      },
      "source": [
        "## import resnet pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGRXJ6aPqoaP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b43b4f14ba61407684f31c979d9cf8f3",
            "e8a7e3753c3047d8aa3449a0c672a840",
            "5413938f9ac84a328fc98efb2d0c731e",
            "89f8bc3c8cf2411084b41252fa3efa97",
            "269d1d5cf2e648b8b5fe9bfe49d43da6",
            "13458ce28c7a421795c41fa972a1e361",
            "620bd842c01a4d7d99f7f2cafcbff97b",
            "94da22ac3f5940088796f4d009c16056"
          ]
        },
        "outputId": "80df0c83-b231-4bfe-c958-5c56049ec178"
      },
      "source": [
        "import torchvision.models as models\n",
        "resnet = models.resnet18(pretrained=True)\n",
        "# resnet152 = models.resnet152(pretrained=True)\n",
        "resnet = resnet.to(device)\n",
        "print(resnet)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/checkpoints/resnet18-5c106cde.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b43b4f14ba61407684f31c979d9cf8f3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=46827520.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_meq4DJLg5L7",
        "colab_type": "text"
      },
      "source": [
        "## freeze the backpropagation except the last layer to train faster"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mR7a8KuBqrMW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "  if feature_extracting:\n",
        "    for param in model.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "set_parameter_requires_grad(resnet, feature_extracting = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trAqBuueqtQ0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "43d9330a-c093-4db0-c5df-fccaa1ebb2dd"
      },
      "source": [
        "num_classes = 1\n",
        "\n",
        "last_input = resnet.fc.in_features\n",
        "resnet.fc = nn.Linear(last_input, num_classes)\n",
        "\n",
        "print(resnet)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53lZ_XJIhEAX",
        "colab_type": "text"
      },
      "source": [
        "# Model setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzzoKlnuqvoB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pretrained_model = resnet.to(device)\n",
        "\n",
        "learning_rate = 0.0001\n",
        "\n",
        "criterion = nn.MSELoss() \n",
        "optimizer = torch.optim.Adam(pretrained_model.parameters(), lr = learning_rate, weight_decay=1e-3)\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "# from torch.utils.tensorboard import SummaryWriter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kabp0AFCINgn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2e8c6cb5-5b2f-4de1-f6e9-f29a0e891a7a"
      },
      "source": [
        "len(train_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9sO-OrYhHCS",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Stvw775pqz4Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b1da9947-8214-4619-d44b-fd5494608d4a"
      },
      "source": [
        "step = 0\n",
        "\n",
        "pretrained_model.train()\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(0,num_epochs):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  total_loss = 0\n",
        "  for i, (img, labels) in enumerate(train_loader):\n",
        "    img = img.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    output = pretrained_model(img)\n",
        "    # print(output)\n",
        "\n",
        "    loss = criterion(output, labels.type_as(output))\n",
        "    \n",
        "    loss.backward()\n",
        "    \n",
        "    optimizer.step()\n",
        "\n",
        "    # Calculate accuracy and total loss\n",
        "    total_loss += loss.item()\n",
        "    # print(loss.item())\n",
        "    total+=1\n",
        "\n",
        "    # Tensorboard logging\n",
        "    # if ((step % 10) == 0):\n",
        "    #   writer.add_scalar(\"Loss/train\", total_loss/total, step)\n",
        "    #   writer.add_scalar(\"Acc/train\", correct/total, step)\n",
        "    info = { 'Loss': loss.item()}\n",
        "    # for tag, value in info.items():\n",
        "    #       logger.add_scalar(tag, value, step+1)\n",
        "\n",
        "    step = step+1\n",
        "    if i % 10 ==0:\n",
        "      print(\"--- Step: %s Loss: %s\" %(i ,total_loss/total))\n",
        "      # print(output)\n",
        "  \n",
        "  print(\"*******************************************************************\")\n",
        "  print(\"Epoch: %s Loss: %s\"%(epoch, total_loss/total))\n",
        "  print(\"*******************************************************************\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:432: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- Step: 0 Loss: 0.689237117767334\n",
            "--- Step: 10 Loss: 0.398796561089429\n",
            "--- Step: 20 Loss: 0.3026107546119463\n",
            "--- Step: 30 Loss: 0.26300137465999973\n",
            "--- Step: 40 Loss: 0.24665747528396\n",
            "*******************************************************************\n",
            "Epoch: 0 Loss: 0.23342230689266455\n",
            "*******************************************************************\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:432: UserWarning: Using a target size (torch.Size([7])) that is different to the input size (torch.Size([7, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- Step: 0 Loss: 0.09508407860994339\n",
            "--- Step: 10 Loss: 0.18046158687634903\n",
            "--- Step: 20 Loss: 0.1668096502267179\n",
            "--- Step: 30 Loss: 0.15024322884217386\n",
            "--- Step: 40 Loss: 0.15136399065575948\n",
            "*******************************************************************\n",
            "Epoch: 1 Loss: 0.15354288077872733\n",
            "*******************************************************************\n",
            "--- Step: 0 Loss: 0.16840969026088715\n",
            "--- Step: 10 Loss: 0.13230211626399646\n",
            "--- Step: 20 Loss: 0.12957317736886798\n",
            "--- Step: 30 Loss: 0.13886621414173034\n",
            "--- Step: 40 Loss: 0.13884920199833264\n",
            "*******************************************************************\n",
            "Epoch: 2 Loss: 0.13357594819820445\n",
            "*******************************************************************\n",
            "--- Step: 0 Loss: 0.20614445209503174\n",
            "--- Step: 10 Loss: 0.10534170913425359\n",
            "--- Step: 20 Loss: 0.1216555026670297\n",
            "--- Step: 30 Loss: 0.11849037714062198\n",
            "--- Step: 40 Loss: 0.12026454126689493\n",
            "*******************************************************************\n",
            "Epoch: 3 Loss: 0.12079409817638605\n",
            "*******************************************************************\n",
            "--- Step: 0 Loss: 0.23133042454719543\n",
            "--- Step: 10 Loss: 0.11729078401218761\n",
            "--- Step: 20 Loss: 0.10085767037456944\n",
            "--- Step: 30 Loss: 0.09861815696762453\n",
            "--- Step: 40 Loss: 0.10156852302209633\n",
            "*******************************************************************\n",
            "Epoch: 4 Loss: 0.10535053669920434\n",
            "*******************************************************************\n",
            "--- Step: 0 Loss: 0.1040821522474289\n",
            "--- Step: 10 Loss: 0.0851529985666275\n",
            "--- Step: 20 Loss: 0.08586226900418599\n",
            "--- Step: 30 Loss: 0.09042096282205274\n",
            "--- Step: 40 Loss: 0.0942764006009916\n",
            "*******************************************************************\n",
            "Epoch: 5 Loss: 0.09656739404991917\n",
            "*******************************************************************\n",
            "--- Step: 0 Loss: 0.14569811522960663\n",
            "--- Step: 10 Loss: 0.0989630205387419\n",
            "--- Step: 20 Loss: 0.09249788398543994\n",
            "--- Step: 30 Loss: 0.08845533364482465\n",
            "--- Step: 40 Loss: 0.08351584787412387\n",
            "*******************************************************************\n",
            "Epoch: 6 Loss: 0.08149477134904136\n",
            "*******************************************************************\n",
            "--- Step: 0 Loss: 0.13802921772003174\n",
            "--- Step: 10 Loss: 0.06944928267462687\n",
            "--- Step: 20 Loss: 0.06881987454280966\n",
            "--- Step: 30 Loss: 0.0718713284380013\n",
            "--- Step: 40 Loss: 0.07246118506825552\n",
            "*******************************************************************\n",
            "Epoch: 7 Loss: 0.07446716770367778\n",
            "*******************************************************************\n",
            "--- Step: 0 Loss: 0.05028051510453224\n",
            "--- Step: 10 Loss: 0.05978031727400693\n",
            "--- Step: 20 Loss: 0.07161939250571388\n",
            "--- Step: 30 Loss: 0.07765480587559362\n",
            "--- Step: 40 Loss: 0.07400298568351966\n",
            "*******************************************************************\n",
            "Epoch: 8 Loss: 0.07222466587858356\n",
            "*******************************************************************\n",
            "--- Step: 0 Loss: 0.03181467205286026\n",
            "--- Step: 10 Loss: 0.06481798501177267\n",
            "--- Step: 20 Loss: 0.06623551054369836\n",
            "--- Step: 30 Loss: 0.05925608828904167\n",
            "--- Step: 40 Loss: 0.05867617827181409\n",
            "*******************************************************************\n",
            "Epoch: 9 Loss: 0.06394324852558582\n",
            "*******************************************************************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVyspIKZhI83",
        "colab_type": "text"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuNBuElUZ2yn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_model_resnet(test_dataloader, net):\n",
        "  # TODO: Insert your code here\n",
        "  ans = []\n",
        "  with torch.no_grad(): \n",
        "    correct  = 0\n",
        "    total  = 0\n",
        "    total_loss = 0\n",
        "    for images,labels in test_dataloader:\n",
        "      images = images.to(device) #why need one more dimension -1, because is the batch\n",
        "      labels = labels.to(device)\n",
        "      outputs = net(images)\n",
        "      loss = criterion(outputs, labels.type_as(output))\n",
        "      total_loss += loss.item()\n",
        "      total+=1\n",
        "      \n",
        "    print('total loss: ', total_loss/total)\n",
        "  return total_loss/total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iu38NUFAaI8d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "186bec9e-d402-431e-dd15-0b0e793473f6"
      },
      "source": [
        "test_model_resnet(test_loader, pretrained_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:432: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "total loss:  0.04997596833189683\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:432: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.04997596833189683"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JWb0hYyakLY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}